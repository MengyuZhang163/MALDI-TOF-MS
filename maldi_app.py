import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from pathlib import Path
import zipfile
import io
import tempfile
import subprocess
import os
import shutil

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="MALDI-TOF MS æ•°æ®å¤„ç†å¹³å°",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #555;
        margin-bottom: 2rem;
    }
    .stAlert {
        border-radius: 10px;
    }
    .upload-box {
        border: 2px dashed #1f77b4;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background-color: #f0f8ff;
    }
    .metric-card {
        background-color: #f8f9fa;
        border-radius: 8px;
        padding: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None
if 'processing_params' not in st.session_state:
    st.session_state.processing_params = {}

def create_r_script(temp_dir, params):
    """ç”Ÿæˆè‡ªé€‚åº”å‚æ•°çš„Rå¤„ç†è„šæœ¬"""
    r_script = f"""
library('MALDIquant')
library('MALDIquantForeign')
library('readxl')

# è‡ªé€‚åº”å‚æ•°ä¼°è®¡å‡½æ•°
estimate_halfWindowSize <- function(spectra, test_sizes = c(10, 20, 50, 90, 150)) {{
  peak_counts <- sapply(test_sizes, function(hw) {{
    test_peaks <- detectPeaks(spectra[[1]], method = "MAD", 
                               halfWindowSize = hw, SNR = 2)
    length(test_peaks@mass)
  }})
  optimal_idx <- which.min(abs(peak_counts - median(peak_counts)))
  return(test_sizes[optimal_idx])
}}

estimate_SNR <- function(spectra, quantile_threshold = 0.95) {{
  all_intensities <- unlist(lapply(spectra, function(s) s@intensity))
  noise_level <- quantile(all_intensities, 0.5)
  signal_level <- quantile(all_intensities, quantile_threshold)
  snr <- signal_level / noise_level
  return(max(2, min(5, round(snr * 0.1))))
}}

estimate_tolerance <- function(spectra) {{
  mz_range <- range(spectra[[1]]@mass)
  resolution <- length(spectra[[1]]@mass) / diff(mz_range)
  rel_tolerance <- 1 / resolution * 10
  return(max(0.002, min(0.01, rel_tolerance)))
}}

# è·¯å¾„è®¾ç½®
train_path <- '{temp_dir}/train/'
valid_path <- '{temp_dir}/valid/'
excel_file <- list.files(train_path, pattern = '\\\\.xlsx$', full.names = TRUE)[1]

# è¯»å–æ ·æœ¬ä¿¡æ¯
samples <- read_excel(excel_file)

# å¯¼å…¥è®­ç»ƒé›†
training_spectra <- importTxt(train_path)
cat(sprintf("å¯¼å…¥äº† %d ä¸ªè®­ç»ƒé›†å…‰è°±\\n", length(training_spectra)))

# å‚æ•°ä¼°è®¡
{'optimal_hw <- ' + str(params['halfWindowSize']) if params['auto_params'] == False else 'optimal_hw <- estimate_halfWindowSize(training_spectra)'}
{'optimal_snr <- ' + str(params['SNR']) if params['auto_params'] == False else 'optimal_snr <- estimate_SNR(training_spectra)'}
{'optimal_tol <- ' + str(params['tolerance']) if params['auto_params'] == False else 'optimal_tol <- estimate_tolerance(training_spectra)'}

cat(sprintf("å‚æ•°è®¾ç½®: halfWindowSize=%d, SNR=%.1f, tolerance=%.4f\\n", 
            optimal_hw, optimal_snr, optimal_tol))

# ä¿å­˜å‚æ•°åˆ°æ–‡ä»¶
params_df <- data.frame(
  parameter = c('halfWindowSize', 'SNR', 'tolerance'),
  value = c(optimal_hw, optimal_snr, optimal_tol)
)
write.csv(params_df, '{temp_dir}/parameters.csv', row.names = FALSE)

# é¢„å¤„ç†è®­ç»ƒé›†
training_spectra <- transformIntensity(training_spectra, method = "sqrt")
training_spectra <- smoothIntensity(training_spectra, method = "SavitzkyGolay", 
                                     halfWindowSize = optimal_hw)
training_spectra <- removeBaseline(training_spectra, method = "SNIP", iterations = 100)
training_spectra <- calibrateIntensity(training_spectra, method = "TIC")

# åˆ†é…æ ‡ç­¾
train_labels <- samples$group[match(
  sapply(training_spectra, function(s) basename(s@metaData$file)),
  samples$file
)]

# è®¡ç®—å¹³å‡è°±
avgSpectra <- averageMassSpectra(training_spectra, labels = train_labels)
avgSpectra <- alignSpectra(avgSpectra, halfWindowSize = optimal_hw,
                           SNR = optimal_snr, tolerance = optimal_tol,
                           warpingMethod = "lowess")

# å¤„ç†éªŒè¯é›†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
if (dir.exists(valid_path) && length(list.files(valid_path, pattern = '\\\\.txt$')) > 0) {{
  validation_spectra <- importTxt(valid_path)
  cat(sprintf("å¯¼å…¥äº† %d ä¸ªéªŒè¯é›†å…‰è°±\\n", length(validation_spectra)))
  
  validation_spectra <- transformIntensity(validation_spectra, method = "sqrt")
  validation_spectra <- smoothIntensity(validation_spectra, method = "SavitzkyGolay", 
                                         halfWindowSize = optimal_hw)
  validation_spectra <- removeBaseline(validation_spectra, method = "SNIP", iterations = 100)
  validation_spectra <- calibrateIntensity(validation_spectra, method = "TIC")
  
  combinedSpectra <- c(avgSpectra, validation_spectra)
}} else {{
  combinedSpectra <- avgSpectra
  validation_spectra <- list()
}}

# å¯¹é½ã€æ£€å³°ã€åˆ†ç®±
alignedCombined <- alignSpectra(combinedSpectra, halfWindowSize = optimal_hw,
                                SNR = optimal_snr, tolerance = optimal_tol,
                                warpingMethod = "lowess")

detectedPeaksCombined <- detectPeaks(alignedCombined, method = "MAD",
                                     halfWindowSize = optimal_hw, SNR = optimal_snr)

binnedPeaksCombined <- binPeaks(detectedPeaksCombined, tolerance = 2)

mat <- intensityMatrix(binnedPeaksCombined, alignedCombined)

# å¤„ç†åˆ—å
bin_centers_highprec <- as.numeric(colnames(mat))
bin_centers_integer <- round(bin_centers_highprec)
colnames(mat) <- paste0("mz_", bin_centers_integer)

# å¤„ç†è¡Œå
n_train_groups <- length(avgSpectra)
n_val_spectra <- length(validation_spectra)
train_group_names <- unique(train_labels)

if (n_val_spectra > 0) {{
  valid_names <- sapply(validation_spectra, function(s) basename(s@metaData$file))
  rownames(mat) <- c(train_group_names, valid_names)
}} else {{
  rownames(mat) <- train_group_names
}}

# ä¿å­˜ç»“æœ
intensity_train <- mat[1:n_train_groups, , drop = FALSE]
write.csv(intensity_train, '{temp_dir}/peak_intensity_train.csv', row.names = TRUE)

if (n_val_spectra > 0) {{
  intensity_validation <- mat[(n_train_groups + 1):(n_train_groups + n_val_spectra), , drop = FALSE]
  write.csv(intensity_validation, '{temp_dir}/peak_intensity_validation.csv', row.names = TRUE)
}}

# ä¿å­˜ç¬¬ä¸€ä¸ªå¹³å‡è°±ç”¨äºå¯è§†åŒ–
first_avg <- avgSpectra[[1]]
viz_data <- data.frame(
  mz = first_avg@mass,
  intensity = first_avg@intensity
)
write.csv(viz_data, '{temp_dir}/spectrum_viz.csv', row.names = FALSE)

cat("å¤„ç†å®Œæˆ!\\n")
"""
    
    script_path = Path(temp_dir) / "process.R"
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(r_script)
    
    return script_path

def run_r_script(script_path):
    """æ‰§è¡ŒRè„šæœ¬"""
    try:
        result = subprocess.run(
            ['Rscript', str(script_path)],
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        return result.stdout, result.stderr, result.returncode
    except subprocess.TimeoutExpired:
        return "", "å¤„ç†è¶…æ—¶ï¼ˆè¶…è¿‡5åˆ†é’Ÿï¼‰", 1
    except FileNotFoundError:
        return "", "æœªæ‰¾åˆ°Rç¯å¢ƒï¼Œè¯·ç¡®ä¿å·²å®‰è£…Rå’Œå¿…è¦çš„åŒ…", 1

def plot_spectrum(df):
    """ç»˜åˆ¶è´¨è°±å›¾"""
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=df['mz'],
        y=df['intensity'],
        mode='lines',
        name='å¼ºåº¦',
        line=dict(color='#1f77b4', width=1),
        fill='tozeroy',
        fillcolor='rgba(31, 119, 180, 0.3)'
    ))
    
    fig.update_layout(
        title='å¹³å‡è´¨è°±å›¾',
        xaxis_title='m/z',
        yaxis_title='ç›¸å¯¹å¼ºåº¦',
        hovermode='x unified',
        template='plotly_white',
        height=500
    )
    
    return fig

def plot_heatmap(df):
    """ç»˜åˆ¶å¼ºåº¦çƒ­å›¾"""
    # å–å‰50ä¸ªæœ€å¤§å³°
    top_cols = df.iloc[:, 1:].sum().nlargest(50).index
    data_subset = df[['è¡Œå'] + list(top_cols)]
    
    fig = px.imshow(
        data_subset.set_index('è¡Œå').T,
        aspect='auto',
        color_continuous_scale='Viridis',
        labels=dict(x="æ ·æœ¬", y="m/z", color="å¼ºåº¦")
    )
    
    fig.update_layout(
        title='å³°å¼ºåº¦çƒ­å›¾ï¼ˆTop 50å³°ï¼‰',
        height=600
    )
    
    return fig

# ========================================
# ä¸»åº”ç”¨ç•Œé¢
# ========================================

st.markdown('<div class="main-header">ğŸ”¬ MALDI-TOF MS æ•°æ®å¤„ç†å¹³å°</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">å¾®ç”Ÿç‰©è´¨è°±æ•°æ®è‡ªåŠ¨åŒ–é¢„å¤„ç†å·¥å…·</div>', unsafe_allow_html=True)

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ“‹ å¤„ç†æµç¨‹")
    st.markdown("""
    1ï¸âƒ£ ä¸Šä¼ è®­ç»ƒé›†æ–‡ä»¶  
    2ï¸âƒ£ ä¸Šä¼ éªŒè¯é›†æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰  
    3ï¸âƒ£ é…ç½®å¤„ç†å‚æ•°  
    4ï¸âƒ£ å¼€å§‹å¤„ç†  
    5ï¸âƒ£ æŸ¥çœ‹ç»“æœå¹¶ä¸‹è½½  
    """)
    
    st.divider()
    
    st.header("âš™ï¸ å‚æ•°é…ç½®")
    
    auto_params = st.checkbox("è‡ªåŠ¨å‚æ•°ä¼°è®¡", value=True, 
                              help="æ ¹æ®æ•°æ®ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä½³å‚æ•°")
    
    if not auto_params:
        st.subheader("æ‰‹åŠ¨å‚æ•°è®¾ç½®")
        halfWindowSize = st.slider("åŠå³°å®½", 10, 200, 90, 10)
        SNR = st.slider("ä¿¡å™ªæ¯”é˜ˆå€¼", 1.0, 10.0, 2.0, 0.5)
        tolerance = st.slider("å¯¹é½å®¹å·®", 0.001, 0.02, 0.008, 0.001, format="%.4f")
    else:
        halfWindowSize, SNR, tolerance = None, None, None
    
    st.session_state.processing_params = {
        'auto_params': auto_params,
        'halfWindowSize': halfWindowSize,
        'SNR': SNR,
        'tolerance': tolerance
    }
    
    st.divider()
    
    st.markdown("""
    ### ğŸ’¡ ä½¿ç”¨æç¤º
    - è®­ç»ƒé›†éœ€åŒ…å«TXTå…‰è°±æ–‡ä»¶å’ŒExcelæ ‡ç­¾æ–‡ä»¶
    - Excelå¿…é¡»æœ‰`file`å’Œ`group`ä¸¤åˆ—
    - éªŒè¯é›†ä»…éœ€TXTæ–‡ä»¶
    """)

# ä¸»å†…å®¹åŒº
tab1, tab2, tab3 = st.tabs(["ğŸ“ æ•°æ®ä¸Šä¼ ", "â–¶ï¸ å¤„ç†ä¸ç»“æœ", "ğŸ“Š æ•°æ®å¯è§†åŒ–"])

with tab1:
    st.header("æ•°æ®ä¸Šä¼ ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("è®­ç»ƒé›†æ–‡ä»¶")
        train_txt_files = st.file_uploader(
            "ä¸Šä¼ è®­ç»ƒé›†TXTæ–‡ä»¶",
            type=['txt'],
            accept_multiple_files=True,
            key='train_txt'
        )
        
        train_excel = st.file_uploader(
            "ä¸Šä¼ æ ‡ç­¾Excelæ–‡ä»¶",
            type=['xlsx', 'xls'],
            key='train_excel',
            help="å¿…é¡»åŒ…å« 'file' å’Œ 'group' ä¸¤åˆ—"
        )
        
        if train_txt_files and train_excel:
            st.success(f"âœ… å·²ä¸Šä¼  {len(train_txt_files)} ä¸ªTXTæ–‡ä»¶å’Œ1ä¸ªExcelæ–‡ä»¶")
    
    with col2:
        st.subheader("éªŒè¯é›†æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰")
        valid_txt_files = st.file_uploader(
            "ä¸Šä¼ éªŒè¯é›†TXTæ–‡ä»¶",
            type=['txt'],
            accept_multiple_files=True,
            key='valid_txt'
        )
        
        if valid_txt_files:
            st.success(f"âœ… å·²ä¸Šä¼  {len(valid_txt_files)} ä¸ªéªŒè¯é›†æ–‡ä»¶")
        else:
            st.info("ğŸ’¡ éªŒè¯é›†ä¸ºå¯é€‰é¡¹")

with tab2:
    st.header("æ•°æ®å¤„ç†")
    
    if st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary", use_container_width=True):
        if not train_txt_files or not train_excel:
            st.error("âŒ è¯·å…ˆä¸Šä¼ è®­ç»ƒé›†æ–‡ä»¶ï¼")
        else:
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
                # åˆ›å»ºä¸´æ—¶ç›®å½•
                temp_dir = tempfile.mkdtemp()
                train_dir = Path(temp_dir) / "train"
                valid_dir = Path(temp_dir) / "valid"
                train_dir.mkdir()
                valid_dir.mkdir()
                
                try:
                    # ä¿å­˜è®­ç»ƒé›†æ–‡ä»¶
                    for txt_file in train_txt_files:
                        with open(train_dir / txt_file.name, 'wb') as f:
                            f.write(txt_file.read())
                    
                    with open(train_dir / train_excel.name, 'wb') as f:
                        f.write(train_excel.read())
                    
                    # ä¿å­˜éªŒè¯é›†æ–‡ä»¶
                    if valid_txt_files:
                        for txt_file in valid_txt_files:
                            with open(valid_dir / txt_file.name, 'wb') as f:
                                f.write(txt_file.read())
                    
                    # ç”Ÿæˆå¹¶æ‰§è¡ŒRè„šæœ¬
                    script_path = create_r_script(temp_dir, st.session_state.processing_params)
                    
                    stdout, stderr, returncode = run_r_script(script_path)
                    
                    if returncode == 0:
                        st.success("âœ… å¤„ç†å®Œæˆï¼")
                        
                        # è¯»å–ç»“æœ
                        results = {}
                        
                        if (Path(temp_dir) / "peak_intensity_train.csv").exists():
                            results['train'] = pd.read_csv(Path(temp_dir) / "peak_intensity_train.csv")
                            results['train'].rename(columns={results['train'].columns[0]: 'è¡Œå'}, inplace=True)
                        
                        if (Path(temp_dir) / "peak_intensity_validation.csv").exists():
                            results['validation'] = pd.read_csv(Path(temp_dir) / "peak_intensity_validation.csv")
                            results['validation'].rename(columns={results['validation'].columns[0]: 'è¡Œå'}, inplace=True)
                        
                        if (Path(temp_dir) / "spectrum_viz.csv").exists():
                            results['spectrum'] = pd.read_csv(Path(temp_dir) / "spectrum_viz.csv")
                        
                        if (Path(temp_dir) / "parameters.csv").exists():
                            results['params'] = pd.read_csv(Path(temp_dir) / "parameters.csv")
                        
                        st.session_state.processed_data = results
                        
                        # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
                        st.subheader("å¤„ç†æ‘˜è¦")
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("è®­ç»ƒé›†æ ·æœ¬æ•°", len(results['train']))
                        
                        with col2:
                            if 'validation' in results:
                                st.metric("éªŒè¯é›†æ ·æœ¬æ•°", len(results['validation']))
                            else:
                                st.metric("éªŒè¯é›†æ ·æœ¬æ•°", "N/A")
                        
                        with col3:
                            st.metric("æ£€æµ‹åˆ°çš„å³°æ•°", len(results['train'].columns) - 1)
                        
                        # æ˜¾ç¤ºå‚æ•°
                        if 'params' in results:
                            st.subheader("ä½¿ç”¨çš„å¤„ç†å‚æ•°")
                            st.dataframe(results['params'], use_container_width=True)
                        
                        # æ˜¾ç¤ºæ—¥å¿—
                        with st.expander("æŸ¥çœ‹å¤„ç†æ—¥å¿—"):
                            st.code(stdout, language='text')
                    
                    else:
                        st.error(f"âŒ å¤„ç†å¤±è´¥ï¼\n\n{stderr}")
                        st.code(stdout, language='text')
                
                except Exception as e:
                    st.error(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
                
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    shutil.rmtree(temp_dir, ignore_errors=True)
    
    st.divider()
    
    # ç»“æœä¸‹è½½
    if st.session_state.processed_data:
        st.subheader("ğŸ“¥ ä¸‹è½½å¤„ç†ç»“æœ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if 'train' in st.session_state.processed_data:
                csv_train = st.session_state.processed_data['train'].to_csv(index=False)
                st.download_button(
                    label="ä¸‹è½½è®­ç»ƒé›†ç»“æœ (CSV)",
                    data=csv_train,
                    file_name="peak_intensity_train.csv",
                    mime="text/csv"
                )
        
        with col2:
            if 'validation' in st.session_state.processed_data:
                csv_valid = st.session_state.processed_data['validation'].to_csv(index=False)
                st.download_button(
                    label="ä¸‹è½½éªŒè¯é›†ç»“æœ (CSV)",
                    data=csv_valid,
                    file_name="peak_intensity_validation.csv",
                    mime="text/csv"
                )

with tab3:
    st.header("æ•°æ®å¯è§†åŒ–")
    
    if st.session_state.processed_data:
        # è´¨è°±å›¾
        if 'spectrum' in st.session_state.processed_data:
            st.subheader("å¹³å‡è´¨è°±å›¾")
            fig_spectrum = plot_spectrum(st.session_state.processed_data['spectrum'])
            st.plotly_chart(fig_spectrum, use_container_width=True)
        
        # çƒ­å›¾
        if 'train' in st.session_state.processed_data:
            st.subheader("è®­ç»ƒé›†å³°å¼ºåº¦çƒ­å›¾")
            fig_heatmap = plot_heatmap(st.session_state.processed_data['train'])
            st.plotly_chart(fig_heatmap, use_container_width=True)
        
        # æ•°æ®é¢„è§ˆ
        st.subheader("æ•°æ®é¢„è§ˆ")
        
        data_view = st.selectbox(
            "é€‰æ‹©æ•°æ®é›†",
            ["è®­ç»ƒé›†", "éªŒè¯é›†"] if 'validation' in st.session_state.processed_data else ["è®­ç»ƒé›†"]
        )
        
        if data_view == "è®­ç»ƒé›†":
            st.dataframe(st.session_state.processed_data['train'], use_container_width=True)
        else:
            st.dataframe(st.session_state.processed_data['validation'], use_container_width=True)
    
    else:
        st.info("ğŸ’¡ è¯·å…ˆåœ¨ã€Œå¤„ç†ä¸ç»“æœã€é¡µé¢å¤„ç†æ•°æ®")

# é¡µè„š
st.divider()
st.markdown("""
<div style='text-align: center; color: #888; padding: 2rem 0;'>
    <p>MALDI-TOF MS æ•°æ®å¤„ç†å¹³å° | Powered by Streamlit & MALDIquant</p>
</div>
""", unsafe_allow_html=True)
